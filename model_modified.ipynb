{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/sinagho/W-Mamba/blob/main/model_modified.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gk_mCoIO5zsU"
   },
   "source": [
    "# Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch torchvision torchaudio --upgrade\n",
    "# !pip install causal-conv1d && pip install mamba-ssm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "wt4VECBt6UCa",
    "outputId": "9286859f-4214-4fa4-bd1d-4b6003eb2b9a"
   },
   "outputs": [],
   "source": [
    "# !pip install torch==2.4.0 torchvision==0.19.0 torchaudio==2.4.0 --index-url https://download.pytorch.org/whl/cu121\n",
    "# !pip uninstall mamba-ssm causal-conv1d\n",
    "# !pip install causal-conv1d && pip install mamba-ssm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mtUIZAUk5zsV",
    "outputId": "4306aece-6691-4cab-b673-c30e69f0daaa"
   },
   "outputs": [],
   "source": [
    "# !pip install triton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jkqwOMqm5zsW",
    "outputId": "dc11c1e2-f962-4c49-b8a8-526f46b05459"
   },
   "outputs": [],
   "source": [
    "# !pip install packaging\n",
    "# !pip install timm==0.4.12\n",
    "# !pip install pytest\n",
    "# !pip install chardet\n",
    "# !pip install yacs\n",
    "# !pip install termcolor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "from functools import partial\n",
    "from typing import Optional, Callable\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.checkpoint as checkpoint\n",
    "from einops import rearrange, repeat\n",
    "from timm.models.layers import DropPath, to_2tuple, trunc_normal_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GsCHw9Os5zsW"
   },
   "source": [
    "# Base Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "from contextlib import redirect_stderr\n",
    "from fvcore.nn import FlopCountAnalysis\n",
    "\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "  \n",
    "def count_flops(model, x):\n",
    "  with redirect_stderr(io.StringIO()):\n",
    "    flops = FlopCountAnalysis(model, (x,))\n",
    "    # flops.count(ignore_modules=[torch.nn.ReLU, torch.nn.ReLU6, torch.nn.SiLU, torch.nn.Identity])\n",
    "    flops_amount = flops.total()\n",
    "  return flops_amount\n",
    "\n",
    "def count_parameters_and_flops(model, x):\n",
    "    params = count_parameters(model)\n",
    "    flops_amount = count_flops(model, x)\n",
    "    return params, flops_amount\n",
    "  \n",
    "def print_parameters_and_flops(model, x, inout=False):\n",
    "    params, flops_amount = count_parameters_and_flops(model, x)\n",
    "    if inout:\n",
    "      output = model(x)\n",
    "      print(f\"Input: {x.shape},\\tOutput: {output.shape}\\n{80*'-'}\")\n",
    "    print(f\"Parameters: {params/1e6:.6f} M,\\tFLOPs: {flops_amount/1e9:.6f} G\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "gwKSX-KX5zsW"
   },
   "outputs": [],
   "source": [
    "DropPath.__repr__ = lambda self: f\"timm.DropPath({self.drop_prob})\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YxvhxdSN5zsY"
   },
   "source": [
    "## Check the details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "GLF68rwO5zsY"
   },
   "outputs": [],
   "source": [
    "# my_model = VSSBlock(hidden_dim = 64).cuda()\n",
    "# print(my_model)\n",
    "# x = torch.randn(1,64,128,128).cuda()\n",
    "# print_parameters_and_flops(my_model, x, inout=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9nNi49xP5zsZ",
    "outputId": "724f0fd8-183c-47fe-a050-0918e3be4c21"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TM06MSx95zsZ"
   },
   "source": [
    "# Make the Models (V1 & V2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "JI1yrVpt5zsZ"
   },
   "outputs": [],
   "source": [
    "from blocks.ssm import SS2D\n",
    "\n",
    "class VSSBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        hidden_dim: int = 0,\n",
    "        drop_path: float = 0,\n",
    "        norm_layer: Callable[..., torch.nn.Module] = partial(nn.LayerNorm, eps=1e-6),\n",
    "        attn_drop_rate: float = 0,\n",
    "        d_state: int = 16,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.ln_1 = norm_layer(hidden_dim)\n",
    "        self.self_attention = SS2D(d_model=hidden_dim, dropout=attn_drop_rate, d_state=d_state, **kwargs)\n",
    "        self.drop_path = DropPath(drop_path)\n",
    "\n",
    "    def forward(self, input: torch.Tensor):\n",
    "        input = input.permute(0, 2, 3, 1).contiguous() # B, C, H, W -> B, H, W, C\n",
    "        x = self.ln_1(input)\n",
    "        x = self.self_attention(x)\n",
    "        x = input + self.drop_path(x)\n",
    "        x = x.permute(0, 3, 1, 2).contiguous() # B, H, W, C -> B, C, H, W\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: torch.Size([1, 64, 128, 128]),\tOutput: torch.Size([1, 64, 128, 128])\n",
      "--------------------------------------------------------------------------------\n",
      "Parameters: 0.055936 M,\tFLOPs: 0.772811 G\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1, 64, 128, 128).cuda() # (B, N, C)\n",
    "block = VSSBlock(hidden_dim=64, drop_path=0.1, attn_drop_rate=0, d_state=16).cuda()\n",
    "print_parameters_and_flops(block, x, inout=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-daFbsoK5zsZ"
   },
   "source": [
    "## V1 & V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Y7tnkjJ65zsZ"
   },
   "outputs": [],
   "source": [
    "# class VSSModule(nn.Module):\n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         hidden_dim: int = 0,\n",
    "#         drop_path: float = 0,\n",
    "#         norm_layer: Callable[..., torch.nn.Module] = partial(nn.LayerNorm, eps=1e-6),\n",
    "#         attn_drop_rate: float = 0,\n",
    "#         d_state: int = 16,\n",
    "#         init_value: float = 1.0,\n",
    "#         vss_block: Callable[..., torch.nn.Module] = VSSBlock,\n",
    "#         **kwargs,\n",
    "#     ):\n",
    "#         super().__init__()\n",
    "#         self.vssm = vss_block(hidden_dim, drop_path, norm_layer, attn_drop_rate, d_state, **kwargs)\n",
    "#         self.lambda_ = nn.Parameter(init_value*torch.ones(hidden_dim,1,1), requires_grad=True)\n",
    "#         self.conv_bbone = nn.Sequential(nn.Conv2d(hidden_dim, hidden_dim, kernel_size=3, stride=1, padding=1, groups=hidden_dim),\n",
    "#                                         nn.BatchNorm2d(num_features=hidden_dim),\n",
    "#                                         nn.LeakyReLU(),\n",
    "#                                         nn.Conv2d(hidden_dim, hidden_dim, kernel_size=1),\n",
    "#                                         nn.BatchNorm2d(num_features=hidden_dim),\n",
    "#                                         nn.SiLU())\n",
    "#         self.beta =  nn.Parameter(init_value*torch.ones(hidden_dim,1,1), requires_grad=True)\n",
    "#         self.mlp = nn.Sequential(nn.Conv2d(hidden_dim, hidden_dim, kernel_size=1),\n",
    "#                                  nn.BatchNorm2d(num_features=hidden_dim),\n",
    "#                                  nn.SiLU())\n",
    "#         def forward(self, x):\n",
    "#             raise NotImplementedError\n",
    "\n",
    "# from models.vmaco import VSSModule\n",
    "\n",
    "# class VSSModuleV1(VSSModule):\n",
    "#     def __init__(self, *args, **kwargs):\n",
    "#         super().__init__(*args, **kwargs)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         y_ssm = self.lambda_ * self.vssm(x)\n",
    "#         y_cnn = self.conv_bbone(y_ssm + x)\n",
    "#         x = y_cnn + self.beta*x\n",
    "#         x = self.mlp(x)\n",
    "#         return x\n",
    "    \n",
    "\n",
    "# class VSSModuleV2(VSSModule):\n",
    "#     def __init__(self, *args, **kwargs):\n",
    "#         super().__init__(*args, **kwargs)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x_vss = self.lambda_ * self.vssm(x)\n",
    "#         x_cnn = self.beta * self.conv_bbone(x_vss + x)\n",
    "#         x = self.mlp(x_vss + x_cnn)\n",
    "#         return x\n",
    "    \n",
    "\n",
    "# from blocks.cnn import CBAM\n",
    "# from blocks.vit import IBIBlock\n",
    "\n",
    "# class VSSModuleV3(VSSModule):\n",
    "#     def __init__(self, *args, **kwargs):\n",
    "#         kwargs['init_value'] = None\n",
    "#         fmap_size = kwargs['fmap_size']        \n",
    "        \n",
    "#         super().__init__(*args, **kwargs)\n",
    "        \n",
    "#         self.cbbam = CBAM(self.hidden_dim, ratio=16, kernel_size=5)\n",
    "#         self.ibi = IBIBlock(fmap_size, \n",
    "#                             window_size=7, \n",
    "#                             dim_in=self.hidden_dim, \n",
    "#                             dim_embed=self.hidden_dim, \n",
    "#                             depths=2, stage_spec='LS', heads=4, \n",
    "#                             attn_drop=0.0, proj_drop=0.0, expansion_mlp=1,\n",
    "#                             drop=0.0, drop_path_rate=0.0, use_dwc_mlp=False,\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x_cbb = self.conv_bbone(x)\n",
    "#         x_cnn = self.cbbam(x_cbb) + x\n",
    "#         x_ibi, _, _ = self.ibi(x_cnn)\n",
    "#         x = x_ibi + x_cnn\n",
    "#         x_vss = self.vssm(x)\n",
    "#         x = self.mlp(x_vss + x)\n",
    "#         return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "gBaec-9y5zsZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VSSModuleV1\n",
      "Input: torch.Size([1, 64, 112, 112]),\tOutput: torch.Size([1, 64, 112, 112])\n",
      "--------------------------------------------------------------------------------\n",
      "Parameters: 0.065408 M,\tFLOPs: 0.713692 G\n",
      "\n",
      "VSSModuleV2\n",
      "Input: torch.Size([1, 64, 112, 112]),\tOutput: torch.Size([1, 64, 112, 112])\n",
      "--------------------------------------------------------------------------------\n",
      "Parameters: 0.065408 M,\tFLOPs: 0.713692 G\n",
      "\n",
      "VSSModuleV3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/.venvs/pytorch/lib/python3.10/site-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3595.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: torch.Size([1, 64, 112, 112]),\tOutput: torch.Size([1, 64, 112, 112])\n",
      "--------------------------------------------------------------------------------\n",
      "Parameters: 0.117626 M,\tFLOPs: 1.505102 G\n"
     ]
    }
   ],
   "source": [
    "from models.vmaco import VSSModuleV1, VSSModuleV2, VSSModuleV3\n",
    "\n",
    "x = torch.randn(1, 64, 112, 112).cuda()\n",
    "\n",
    "print(\"VSSModuleV1\")\n",
    "model1 = VSSModuleV1(hidden_dim=64, vss_block=VSSBlock).cuda()\n",
    "print_parameters_and_flops(model1, x, inout=True)\n",
    "\n",
    "print(\"\\nVSSModuleV2\")\n",
    "model2 = VSSModuleV2(hidden_dim=64, vss_block=VSSBlock).cuda()\n",
    "print_parameters_and_flops(model2, x, inout=True)\n",
    "\n",
    "print(\"\\nVSSModuleV3\")\n",
    "model3 = VSSModuleV3(fmap_size=112, hidden_dim=64, vss_block=VSSBlock).cuda()\n",
    "print_parameters_and_flops(model3, x, inout=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "f1PNrj2a5zsa"
   },
   "outputs": [],
   "source": [
    "class BaseModule(nn.Module):\n",
    "    def _init_weights(self, m: nn.Module):\n",
    "        for name, p in m.named_parameters():\n",
    "            if name in [\"out_proj.weight\"]:\n",
    "                p = p.clone().detach_() # fake init, just to keep the seed ....\n",
    "                nn.init.kaiming_uniform_(p, a=math.sqrt(5))\n",
    "\n",
    "        if isinstance(m, nn.Linear):\n",
    "            trunc_normal_(m.weight, std=.02)\n",
    "            if isinstance(m, nn.Linear) and m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.LayerNorm):\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "            nn.init.constant_(m.weight, 1.0)\n",
    "            \n",
    "\n",
    "class VSSLayer(BaseModule):\n",
    "    \"\"\" A layer for one stage.\n",
    "    Args:\n",
    "        dim (int): Number of input channels.\n",
    "        depth (int): Number of blocks.\n",
    "        drop (float, optional): Dropout rate. Default: 0.0\n",
    "        attn_drop (float, optional): Attention dropout rate. Default: 0.0\n",
    "        drop_path (float | tuple[float], optional): Stochastic depth rate. Default: 0.0\n",
    "        norm_layer (nn.Module, optional): Normalization layer. Default: nn.LayerNorm\n",
    "        downsample (nn.Module | None, optional): Downsample layer at the end of the layer. Default: None\n",
    "        use_checkpoint (bool): Whether to use checkpointing to save memory. Default: False.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim,\n",
    "        depth,\n",
    "        attn_drop=0.,\n",
    "        drop_path=0.,\n",
    "        norm_layer=nn.LayerNorm,\n",
    "        upsample=None,\n",
    "        downsample=None,\n",
    "        use_checkpoint=False,\n",
    "        d_state=16,\n",
    "        init_value: float =1.0,\n",
    "        vss_module: Callable[..., torch.nn.Module] = partial(VSSModuleV1, vss_block=VSSBlock),\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.use_checkpoint = use_checkpoint\n",
    "        self.blocks = nn.ModuleList([vss_module(\n",
    "            hidden_dim = dim,\n",
    "            drop_path = drop_path[i] if isinstance(drop_path, list) else drop_path,\n",
    "            norm_layer = norm_layer,\n",
    "            attn_drop_rate = attn_drop,\n",
    "            d_state = d_state,\n",
    "            init_value = init_value,\n",
    "            **kwargs,\n",
    "        ) for i in range(depth)])\n",
    "\n",
    "        self.upsample = upsample(dim, norm_layer=norm_layer) if callable(upsample) else None\n",
    "        self.downsample = downsample(dim, norm_layer=norm_layer) if callable(downsample) else None\n",
    "        self.apply(self._init_weights)        \n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.upsample: x = self.upsample(x)\n",
    "        for blk in self.blocks:\n",
    "            x = checkpoint.checkpoint(blk, x) if self.use_checkpoint else blk(x)\n",
    "        if self.downsample: x = self.downsample(x)\n",
    "        return x\n",
    "\n",
    "VSSLayerV1 = partial(VSSLayer, vss_module=VSSModuleV1)\n",
    "VSSLayerV2 = partial(VSSLayer, vss_module=VSSModuleV2)\n",
    "\n",
    "VSSLayer_down_V1 = partial(VSSLayerV1, upsample=None)\n",
    "VSSLayer_down_V2 = partial(VSSLayerV2, upsample=None)\n",
    "VSSLayer_up_V1 = partial(VSSLayerV1, downsample=None)\n",
    "VSSLayer_up_V2 = partial(VSSLayerV2, downsample=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RilfPPNv5zsa",
    "outputId": "24fd224d-4e9c-486c-a5c5-c7f45547f2e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: torch.Size([1, 64, 112, 112]),\tOutput: torch.Size([1, 64, 112, 112])\n",
      "--------------------------------------------------------------------------------\n",
      "Parameters: 0.235252 M,\tFLOPs: 3.010205 G\n"
     ]
    }
   ],
   "source": [
    "layer = VSSLayer(fmap_size=112, dim=64, depth=2, vss_module=VSSModuleV3).cuda()\n",
    "a = torch.randn(1, 64, 112, 112).cuda()\n",
    "print_parameters_and_flops(layer, a, inout=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wCzVaUmU5zsb"
   },
   "source": [
    "## Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "-PkuQ9F45zsb"
   },
   "outputs": [],
   "source": [
    "from blocks.patch import PatchEmbed2D, PatchMerging2D, PatchExpand2D, Final_PatchExpand2D\n",
    "\n",
    "\n",
    "class VMACO(BaseModule):\n",
    "    def __init__(self, patch_size=4, in_chans=3, num_classes=1000, depths=[2, 2, 9, 2], depths_decoder=[2, 9, 2, 2],\n",
    "                 dims=[96, 192, 384, 768], dims_decoder=[768, 384, 192, 96], d_state=16, drop_rate=0., attn_drop_rate=0., drop_path_rate=0.1,\n",
    "                 norm_layer=nn.LayerNorm, patch_norm=True, use_checkpoint=False, \n",
    "                 vss_layer=VSSLayerV1,\n",
    "                 spatial_size=224, **kwargs):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.num_layers = len(depths)\n",
    "        if isinstance(dims, int):\n",
    "            dims = [int(dims * 2 ** i_layer) for i_layer in range(self.num_layers)]\n",
    "        self.embed_dim = dims[0]\n",
    "        self.num_features = dims[-1]\n",
    "        self.dims = dims\n",
    "        self.patch_embed = PatchEmbed2D(patch_size, in_chans, embed_dim=self.embed_dim, norm_layer=norm_layer if patch_norm else None)\n",
    "\n",
    "        # WASTED absolute position embedding ======================\n",
    "        self.ape = False\n",
    "        # self.ape = False\n",
    "        # drop_rate = 0.0\n",
    "        if self.ape:\n",
    "            self.patches_resolution = self.patch_embed.patches_resolution\n",
    "            self.absolute_pos_embed = nn.Parameter(torch.zeros(1, *self.patches_resolution, self.embed_dim))\n",
    "            trunc_normal_(self.absolute_pos_embed, std=.02)\n",
    "        self.pos_drop = nn.Dropout(p=drop_rate)\n",
    "\n",
    "        dpr = [x.item() for x in torch.linspace(0, drop_path_rate, sum(depths))]  # stochastic depth decay rule\n",
    "        dpr_decoder = [x.item() for x in torch.linspace(0, drop_path_rate, sum(depths_decoder))][::-1]\n",
    "\n",
    "        fmas = [56, 28, 14, 7]\n",
    "        self.layers_down = nn.ModuleList([\n",
    "            vss_layer(\n",
    "                dim=dims[i_layer],\n",
    "                depth=depths[i_layer],\n",
    "                d_state=d_state,\n",
    "                drop=drop_rate,\n",
    "                attn_drop=attn_drop_rate,\n",
    "                drop_path=dpr[sum(depths[:i_layer]):sum(depths[:i_layer + 1])],\n",
    "                norm_layer=norm_layer,\n",
    "                downsample=PatchMerging2D if (i_layer < self.num_layers - 1) else None,\n",
    "                use_checkpoint=use_checkpoint,\n",
    "                fmap_size=fmas[i_layer],\n",
    "\n",
    "            ) for i_layer in range(self.num_layers)\n",
    "        ])\n",
    "\n",
    "        fmas = [56, 28, 14, 7][::-1]\n",
    "        self.layers_up = nn.ModuleList([\n",
    "            vss_layer(\n",
    "                dim=dims_decoder[i_layer],\n",
    "                depth=depths_decoder[i_layer],\n",
    "                d_state=d_state,\n",
    "                drop=drop_rate,\n",
    "                attn_drop=attn_drop_rate,\n",
    "                drop_path=dpr_decoder[sum(depths_decoder[:i_layer]):sum(depths_decoder[:i_layer + 1])],\n",
    "                norm_layer=norm_layer,\n",
    "                upsample=PatchExpand2D if (i_layer != 0) else None,\n",
    "                use_checkpoint=use_checkpoint,\n",
    "                fmap_size=fmas[i_layer],\n",
    "            ) for i_layer in range(self.num_layers)\n",
    "        ])\n",
    "\n",
    "        self.final_up = Final_PatchExpand2D(dim=dims_decoder[-1], dim_scale=4, norm_layer=norm_layer)\n",
    "        self.final_conv = nn.Conv2d(dims_decoder[-1]//4, num_classes, 1)\n",
    "        # self.norm = norm_layer(self.num_features)\n",
    "        # self.avgpool = nn.AdaptiveAvgPool1d(1)\n",
    "        # self.head = nn.Linear(self.num_features, num_classes) if num_classes > 0 else nn.Identity()\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    @torch.jit.ignore\n",
    "    def no_weight_decay(self):\n",
    "        return {'absolute_pos_embed'}\n",
    "\n",
    "    @torch.jit.ignore\n",
    "    def no_weight_decay_keywords(self):\n",
    "        return {'relative_position_bias_table'}\n",
    "\n",
    "    def forward_features(self, x):\n",
    "        skip_list = []\n",
    "        x = self.patch_embed(x)\n",
    "        if self.ape:\n",
    "            x = x + self.absolute_pos_embed\n",
    "        x = self.pos_drop(x)\n",
    "        for layer in self.layers_down:\n",
    "            skip_list.append(x)\n",
    "            x = layer(x)\n",
    "        return x, skip_list\n",
    "\n",
    "    def forward_features_up(self, x, skip_list):\n",
    "        for inx, layer_up in enumerate(self.layers_up):\n",
    "            x = layer_up(x) if inx == 0 else layer_up(x+skip_list[-inx])\n",
    "        return x\n",
    "\n",
    "    def forward_final(self, x):\n",
    "        x = self.final_up(x)\n",
    "        x = self.final_conv(x)\n",
    "        return x\n",
    "\n",
    "    def forward_backbone(self, x):\n",
    "        x = self.patch_embed(x)\n",
    "        if self.ape:\n",
    "            x = x + self.absolute_pos_embed\n",
    "        x = self.pos_drop(x)\n",
    "        for layer in self.layers_down:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, skip_list = self.forward_features(x)\n",
    "        x = self.forward_features_up(x, skip_list)\n",
    "        x = self.forward_final(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cYB3-aIH5zsb",
    "outputId": "71668058-9bae-4201-8431-1d29a9f2ebb0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VMACO V1\n",
      "Input: torch.Size([1, 3, 224, 224]),\tOutput: torch.Size([1, 1000, 224, 224])\n",
      "--------------------------------------------------------------------------------\n",
      "Parameters: 54.917176 M,\tFLOPs: 10.533784 G\n",
      "\n",
      "VMACO V2\n",
      "Input: torch.Size([1, 3, 224, 224]),\tOutput: torch.Size([1, 1000, 224, 224])\n",
      "--------------------------------------------------------------------------------\n",
      "Parameters: 54.917176 M,\tFLOPs: 10.533784 G\n",
      "\n",
      "VMACO V3\n",
      "Input: torch.Size([1, 3, 224, 224]),\tOutput: torch.Size([1, 1000, 224, 224])\n",
      "--------------------------------------------------------------------------------\n",
      "Parameters: 118.183300 M,\tFLOPs: 21.659133 G\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(1, 3, 224, 224).cuda()\n",
    "\n",
    "print(\"VMACO V1\")\n",
    "model_v1 = VMACO(vss_layer=VSSLayerV1).cuda()\n",
    "print_parameters_and_flops(model_v1, a, inout=True)\n",
    "\n",
    "print(\"\\nVMACO V2\")\n",
    "model_v2 = VMACO(vss_layer=VSSLayerV2).cuda()\n",
    "print_parameters_and_flops(model_v2, a, inout=True)\n",
    "\n",
    "print(\"\\nVMACO V3\")\n",
    "model_v3 = VMACO(vss_layer=partial(VSSLayer, vss_module=VSSModuleV3)).cuda()\n",
    "print_parameters_and_flops(model_v3, a, inout=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VMACO V1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: torch.Size([1, 3, 224, 224]),\tOutput: torch.Size([1, 1000, 224, 224])\n",
      "--------------------------------------------------------------------------------\n",
      "Parameters: 54.917176 M,\tFLOPs: 10.533784 G\n",
      "\n",
      "VMACO V2\n",
      "Input: torch.Size([1, 3, 224, 224]),\tOutput: torch.Size([1, 1000, 224, 224])\n",
      "--------------------------------------------------------------------------------\n",
      "Parameters: 54.917176 M,\tFLOPs: 10.533784 G\n"
     ]
    }
   ],
   "source": [
    "# import time\n",
    "# import math\n",
    "# from functools import partial\n",
    "# from typing import Optional, Callable\n",
    "\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "# import torch.utils.checkpoint as checkpoint\n",
    "# from einops import rearrange, repeat\n",
    "# from timm.models.layers import DropPath, to_2tuple, trunc_normal_\n",
    "# import io\n",
    "# from contextlib import redirect_stderr\n",
    "# from fvcore.nn import FlopCountAnalysis\n",
    "\n",
    "\n",
    "# def count_parameters(model):\n",
    "#     return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "  \n",
    "# def count_flops(model, x):\n",
    "#   with redirect_stderr(io.StringIO()):\n",
    "#     flops = FlopCountAnalysis(model, (x,))\n",
    "#     # flops.count(ignore_modules=[torch.nn.ReLU, torch.nn.ReLU6, torch.nn.SiLU, torch.nn.Identity])\n",
    "#     flops_amount = flops.total()\n",
    "#   return flops_amount\n",
    "\n",
    "# def count_parameters_and_flops(model, x):\n",
    "#     params = count_parameters(model)\n",
    "#     flops_amount = count_flops(model, x)\n",
    "#     return params, flops_amount\n",
    "  \n",
    "# def print_parameters_and_flops(model, x, inout=False):\n",
    "#     params, flops_amount = count_parameters_and_flops(model, x)\n",
    "#     if inout:\n",
    "#       output = model(x)\n",
    "#       print(f\"Input: {x.shape},\\tOutput: {output.shape}\\n{80*'-'}\")\n",
    "#     print(f\"Parameters: {params/1e6:.6f} M,\\tFLOPs: {flops_amount/1e9:.6f} G\")\n",
    "\n",
    "\n",
    "from models.vmaco import VMACO, VSSLayerV1, VSSLayerV2\n",
    "\n",
    "a = torch.randn(1, 3, 224, 224).cuda()\n",
    "\n",
    "print(\"VMACO V1\")\n",
    "model_v1 = VMACO(vss_layer=VSSLayerV1).cuda()\n",
    "print_parameters_and_flops(model_v1, a, inout=True)\n",
    "\n",
    "print(\"\\nVMACO V2\")\n",
    "model_v2 = VMACO(vss_layer=VSSLayerV2).cuda()\n",
    "print_parameters_and_flops(model_v2, a, inout=True)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
